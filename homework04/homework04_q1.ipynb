{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import linear_model\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Propensity score matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "We load the data from the provided csv file. We observe that the categorical variables are encoded using dummy varibales, i.e. binary variables. We are going to stick with this encoding as it is advantegous for the regression task that we are going to perform later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_data = pd.read_csv(\"lalonde.csv\")\n",
    "lalonde_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A naive analysis\n",
    "\n",
    "To begin with, we compare the distribution of the outcome variable (re78) between the two groups in a naive way, that is we ignore the other features in this analysis.\n",
    "\n",
    "We use the following methods for the comparison:\n",
    "\n",
    "A. plots:\n",
    "1. boxplots\n",
    "2. histograms\n",
    "3. QQ plots\n",
    "\n",
    "B. numbers:\n",
    "1. summary of descriptive statistics\n",
    "2. ------ test ----- TODO\n",
    "\n",
    "As all the parts of the analysis of numerical features  also in the subsequent tasks will be based on this methods we define helping functions encapsulating this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treat = {0: 'treated', 1: 'control'}\n",
    "\n",
    "def draw_box(df, col):\n",
    "    \"\"\"Draw a box plot for the values of the specified column for each of the two groups\"\"\"\n",
    "    df.boxplot(by='treat', column=col, figsize = [10, 7])\n",
    "\n",
    "def draw_hist(df, col):\n",
    "    \"\"\"Draw histograms and kernel density estimation plots for the specified column.\n",
    "    Two plots are created for the two groups but displayed in two overlapping layers for comparison.\n",
    "    \"\"\"\n",
    "    fig_hist, axs_hist = plt.subplots(nrows=2)\n",
    "    df.groupby(\"treat\")[col].plot(kind='kde', ax=axs_hist[1])\n",
    "    axs_hist[1].set_xlabel(col)\n",
    "    groups = df.groupby(\"treat\")[col]\n",
    "    for k, v in groups:\n",
    "        v.hist(label=treat[k], alpha=.75, ax=axs_hist[0], bins=15, range=[df[col].min(), df[col].max()], figsize = [10, 7])\n",
    "    axs_hist[0].legend()\n",
    "    axs_hist[0].set_ylabel('number of participants')\n",
    "    \n",
    "\n",
    "def draw_qqs(df, col):\n",
    "    \"\"\"Draw a QQ plot for both groups to find out more about the distribution of the data.\n",
    "    NB: A comparison to a normal distribution with fitted parameters is performed.\"\"\"\n",
    "    fig_qq, axs_qq = plt.subplots(nrows=2, figsize=(10, 20))\n",
    "    stats.probplot(df[df.treat == 0][col], dist=\"norm\", plot=axs_qq[0])\n",
    "    axs_qq[0].set_title('Control Group')\n",
    "    stats.probplot(df[df.treat == 1][col], dist=\"norm\", plot=axs_qq[1])\n",
    "    axs_qq[1].set_title('Treated Group')\n",
    "    plt.show()\n",
    "    \n",
    "def get_summary(df, col):\n",
    "    \"\"\"Print summary statistics for both groups.\"\"\"\n",
    "    print('Control group')\n",
    "    print('================================================')\n",
    "    print(df[df.treat == 0][col].describe())\n",
    "    print('Treated group')\n",
    "    print('================================================')\n",
    "    print(df[df.treat == 1][col].describe())\n",
    "\n",
    "def test(df, col):\n",
    "    \"\"\"TODO\"\"\" #can same test be used everywhere???? better to perform test after interpreting plot????\n",
    "    # better not to always display all of them but chose????? incrementally\n",
    "    #TODO use different test - data not normally distributed, willcoxon gives error\n",
    "    print(stats.ttest_ind(df[df.treat == 0][col], df[df.treat == 1][col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore we define a funciton that invokes all those functions for a numerical feature and prints the output in a structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_numeric(df, col):    \n",
    "    \"\"\"Perform analysis for a numerical feature and pretty print result.\"\"\"\n",
    "    print('=================================================================================')\n",
    "    print('                                  ', col)\n",
    "    print('=================================================================================')\n",
    "    draw_box(df, col)\n",
    "    draw_hist(df, col)\n",
    "    draw_qqs(df, col)\n",
    "    print()\n",
    "    get_summary(df, col)\n",
    "    print()\n",
    "    test(df, col)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now analyse the distribution of the 're78' feature in the two groups. For the interpretation see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_numeric(lalonde_data, 're78')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(Naive) Conclusions:** .... TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A closer look at the data\n",
    "\n",
    "In order to get a better feeling for whether our naive analysis was appropriate we also compare the distributions of the other covariates. To begin with, we interpret the numerical features in using the same strategy as in Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['age', 'educ', 're74', 're75']:\n",
    "    analyse_numeric(lalonde_data, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interpretation:** .... TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of categorical columns\n",
    "\n",
    "It remains to take a closer look at the categorical variables. As the methods used above are not appropriate for categorical variables , we need new functions for the analysis (For example, there is no point in drawing histograms for categrical variables, the thing to use here are bar plots.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bar(df, col):\n",
    "    '''Draw a bar plot of the number of values in each category for the two groups'''\n",
    "    df_grouped = df.groupby(['treat', col])[col].count()\n",
    "    df_grouped = df_grouped.unstack()\n",
    "    pl = df_grouped.plot(kind='bar', figsize=[5,5])\n",
    "    pl.set_title(col)\n",
    "    pl.set_ylabel('number of participants')\n",
    "    pl.set_xlabel('group')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add more analysis...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the race feature some preprocessing is needed in order to be able to draw a meaningful bar plot. Especially, the data frame does not contain a column for white people. We assume that individuals are white in case they are neither black nor hispanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_race(df):\n",
    "    '''Draw a bar plot for the race feature.'''\n",
    "    df['white'] = (~(df['black'].astype(bool) | df['hispan'].astype(bool))).astype(int)\n",
    "    race = df[['white', 'black', 'hispan']].stack()\n",
    "    df.drop('white', 1)\n",
    "    race = pd.Series(pd.Categorical(race[race!=0].index.get_level_values(1)))\n",
    "    race_group = pd.concat([df.treat, race], axis=1, keys=['treat', 'race'])\n",
    "    draw_bar(race_group, 'race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the significance test we use Fishers exact test --- TODO justification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fisher(df, col):\n",
    "    '''Perform fishers exact test'''\n",
    "    print('Fisher exact test')\n",
    "    print('================================================')\n",
    "    #compute contingency table\n",
    "    df['neg'] = df[col].apply(lambda x: 1-x)\n",
    "    table = df.groupby(df.treat)[col, 'neg'].sum()\n",
    "    df.drop('neg', axis=1)\n",
    "    #perform test\n",
    "    print(stats.fisher_exact(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_categoric(df, col=None):    \n",
    "    \"\"\"Perform analysis for a categorical feature and pretty print result.\"\"\"\n",
    "    print('=================================================================================')\n",
    "    print('                                  ', col)\n",
    "    print('=================================================================================')\n",
    "    if(col == None):\n",
    "        plot_race(df)\n",
    "        print()\n",
    "        print()\n",
    "    else:\n",
    "        draw_bar(df, col)\n",
    "        print()\n",
    "        get_summary(df, col)\n",
    "        print()\n",
    "        test_fisher(df, col)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use those functions for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['married', 'nodegree']: \n",
    "    analyse_categoric(lalonde_data, col)\n",
    "\n",
    "analyse_categoric(lalonde_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A propensity score model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "logistic = logistic.fit(lalonde_data.drop(lalonde_data.columns[[0, 1, -1]], axis=1), lalonde_data.treat)\n",
    "propensity_scores = logistic.predict_proba(lalonde_data.drop(lalonde_data.columns[[0, 1, -1]], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(logistic.classes_)\n",
    "print(propensity_scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_data['propensity'] = propensity_scores[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Balancing the dataset via matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:1, without replacement\n",
    "optimal matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = pd.merge(lalonde_data.reset_index()[lalonde_data.treat == 1].assign(key=0), lalonde_data.reset_index()[lalonde_data.treat == 0].assign(key=0), on='key').drop('key', axis=1)\n",
    "#print(graph_data.head())\n",
    "graph_data['weight'] = 1 - np.abs(graph_data['propensity_x'] - graph_data['propensity_y'])\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(zip(graph_data.index_x, graph_data.index_y, graph_data.weight))\n",
    "matching = nx.max_weight_matching(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching) == 2 * len(lalonde_data[lalonde_data.treat == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo remove :-)\n",
    "for key, value in matching.items():\n",
    "    if(matching[value]!=key):\n",
    "        print('sad storry')\n",
    "print('juhu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_data_balanced = lalonde_data.iloc[list(matching.keys())]\n",
    "lalonde_data_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare outcomes: see 1 and 2 + techniques from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "lalonde_data_balanced.groupby(\"treat\").re78.plot(kind='kde', ax=axs[1])\n",
    "lalonde_data_balanced.groupby(\"treat\").re78.hist(alpha=0.4, ax=axs[0], range=[lalonde_data_balanced.re78.min(), lalonde_data_balanced.re78.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform same analysis as in 1 and 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['age', 'educ', 're74', 're75', 're78']:\n",
    "    analyse_numeric(lalonde_data_balanced, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['married', 'nodegree']: \n",
    "    analyse_categoric(lalonde_data_balanced, col)\n",
    "\n",
    "analyse_categoric(lalonde_data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo add test for categoric\n",
    "#it somehow would make more sense for race ro see ratios..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Balancing the groups further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify \"the problematic feature\": if different in this feature: add very high penalty to weight, oder: direkt in join auf equality filtern :P\n",
    "\n",
    "problenatic features: age, race\n",
    "\n",
    "Further balance for race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = pd.merge(lalonde_data.reset_index()[lalonde_data.treat == 1], lalonde_data.reset_index()[lalonde_data.treat == 0], on='age')\n",
    "#print(graph_data.head())\n",
    "graph_data['weight'] = 1 - np.abs(graph_data['propensity_x'] - graph_data['propensity_y'])\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(zip(graph_data.index_x, graph_data.index_y, graph_data.weight))\n",
    "matching = nx.max_weight_matching(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_data_balanced = lalonde_data.iloc[list(matching.keys())]\n",
    "lalonde_data_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['age', 'educ', 're74', 're75', 're78']:\n",
    "    analyse_numeric(lalonde_data_balanced, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['married', 'nodegree']: \n",
    "    analyse_categoric(lalonde_data_balanced, col)\n",
    "\n",
    "analyse_categoric(lalonde_data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo add test for categoric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A less naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark that sensitivity analysis would be good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_numeric(..., 're78')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
